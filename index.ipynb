{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks - Recap\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "The key takeaways from this section include:\n",
    "\n",
    "### Neural Networks\n",
    "\n",
    "* Neural networks are powerful models that can be customized and tweaked using various amounts of nodes, layers, etc.\n",
    "* The most basic neural networks are single-layer densely connected neural networks, which have very similar properties as logistic regression models\n",
    "* Compared to more traditional statistics and ML techniques, neural networks perform particularly well when using unstructured data\n",
    "* Apart from densely connected networks, other types of neural networks include convolutional neural networks, recurrent neural networks, and generative adversarial neural networks \n",
    "* When working with image data, it's important to understand how image data is stored when working with them in Python\n",
    "* Logistic regression can be seen as a single-layer neural network with a sigmoid activation function\n",
    "* Neural networks use loss and cost functions to minimize the \"loss\", which is a function that summarizes the difference between the actual outcome (eg. pictures contain Santa or not) and the model prediction (whether the model correctly identifies pictures with Santa)\n",
    "* Backward and forward propagation are used to estimate the so-called \"model weights\"\n",
    "* Adding more layers to neural networks can substantially increase model performance\n",
    "* Several activations can be used in model nodes, you can explore with different types and evaluate how it affects performance\n",
    "\n",
    "### Deep Neural Networks\n",
    "\n",
    "* Deep neural network representations can lighten the burden and automate certain tasks of heavy data preprocessing\n",
    "* Deep representations need exponentially fewer hidden units than shallow networks, to obtain the same performance\n",
    "* Parameter initialization, forward propagation, cost function evaluation, and backward propagation are again the cornerstones of deep networks\n",
    "* Tensors are the building blocks of neural networks and a good understanding of them and how to use them in Python is crucial\n",
    "* Scalars can be seen as 0-D tensors. Vectors can be seen as 1-D tensors, and matrices as 2-D tensors\n",
    "* The usage of tensors reaches beyond matrices: tensors can have N dimensions\n",
    "* Tensors can be created and manipulated using NumPy\n",
    "* Keras makes building neural networks in Python easy, and you learned how to do that in this section\n",
    "* You can use Keras to do some NLP as well, e.g. for tokenization "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
